{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38d184c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.utils.data import ConcatDataset, DataLoader, Subset\n",
    "from base_model import BaseModel\n",
    "import pickle\n",
    "import numpy as np\n",
    "import random\n",
    "import ast\n",
    "import torch\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import interp1d\n",
    "import torch.nn.functional as F\n",
    "from dataset import get_dataset,get_imagenet\n",
    "from collections import Counter\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03ae3125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attack_device:cuda:0\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(7)\n",
    "random.seed(7)\n",
    "np.random.seed(7)\n",
    "device = f\"cuda:{0}\"\n",
    "cudnn.benchmark = True\n",
    "print(f\"attack_device:{device}\")\n",
    "input_dim = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "313fe371-5f0d-4991-815c-220378a8ea05",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"mini_imagenet\"\n",
    "model_name = \"vgg16\"\n",
    "num_cls = 100\n",
    "shadow_num = 5\n",
    "compress_name = \"l1unstructure\"\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa73031e-0187-4201-883d-b85b02781f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_folder_original = f\"results/{dataset_name}_{model_name}\"\n",
    "save_folder_compress = f\"results_compress/{dataset_name}_{model_name}_{compress_name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2727b18b-5261-4918-acc1-251e1e0cc745",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = f\"{save_folder_original}/data_index.pkl\"\n",
    "with open(data_path, 'rb') as f:\n",
    "    victim_train_list, victim_test_list, attack_split_list = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "617111a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Data Size: 60000, Victim Train Size: 8000, Victim Test Size: 8000\n"
     ]
    }
   ],
   "source": [
    "trainset, testset = get_dataset(dataset_name)\n",
    "total_dataset = ConcatDataset([trainset, testset])\n",
    "total_size = len(total_dataset)\n",
    "data_path = f\"{save_folder_compress}/inference_data_index.pkl\"\n",
    "    \n",
    "with open(data_path, 'rb') as f:\n",
    "    inference_victim_train_list, inference_victim_test_list, inference_attack_split_list = pickle.load(f)\n",
    "\n",
    "victim_train_dataset = Subset(total_dataset, inference_victim_train_list)\n",
    "victim_test_dataset = Subset(total_dataset, inference_victim_test_list)\n",
    "\n",
    "victim_train_loader = DataLoader(victim_train_dataset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=False)\n",
    "victim_test_loader = DataLoader(victim_test_dataset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f20c1af-2773-4565-9b83-115875587210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v-------------\n"
     ]
    }
   ],
   "source": [
    " # Load victim model\n",
    "victim_model_save_folder = save_folder_original + \"/victim_model\"\n",
    "victim_model_path = f\"{victim_model_save_folder}/best.pth\"\n",
    "victim_model = BaseModel(dataset_name, model_name, num_cls=num_cls, input_dim=input_dim, device=device)\n",
    "victim_model.load(victim_model_path)\n",
    "\n",
    "victim_original_in_loss, victim_in_target, victim_original_in_predicts, victim_original_in_state = victim_model.predict_target_loss(victim_train_loader)\n",
    "victim_original_out_loss, victim_out_target, victim_original_out_predicts, victim_original_out_state = victim_model.predict_target_loss(victim_test_loader)\n",
    "sort_victim_original_in = torch.argsort(victim_original_in_predicts, dim=1, descending=False)\n",
    "sort_victim_original_out = torch.argsort(victim_original_out_predicts, dim=1, descending=False)\n",
    "victim_original_in_predicts = torch.gather(victim_original_in_predicts, 1, sort_victim_original_in)\n",
    "victim_original_out_predicts = torch.gather(victim_original_out_predicts, 1, sort_victim_original_out)\n",
    "victim_original_in_loss = victim_original_in_loss.unsqueeze(1)\n",
    "victim_original_out_loss = victim_original_out_loss.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0fa61742-0e38-4ee4-9dd6-0327d98c7b96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Compress Model from results_pruned/1_mini_imagenet_vgg16_l1unstructure_0.6/victim_model\n",
      "v-------------\n",
      "Victim Compress Model Train: Accuracy 91.250, Loss 0.328\n",
      "Victim Compress Model Test: Accuracy 73.838, Loss 1.131\n",
      "Load Compress Model from results_pruned/1_mini_imagenet_vgg16_l1unstructure_0.7/victim_model\n",
      "v-------------\n",
      "Victim Compress Model Train: Accuracy 91.275, Loss 0.337\n",
      "Victim Compress Model Test: Accuracy 73.862, Loss 1.115\n",
      "Load Compress Model from results_pruned/1_mini_imagenet_vgg16_l1unstructure_0.8/victim_model\n",
      "v-------------\n",
      "Victim Compress Model Train: Accuracy 89.888, Loss 0.388\n",
      "Victim Compress Model Test: Accuracy 73.612, Loss 1.083\n",
      "Load Compress Model from results_pruned/1_mini_imagenet_vgg16_l1unstructure_0.9/victim_model\n",
      "v-------------\n",
      "Victim Compress Model Train: Accuracy 86.625, Loss 0.517\n",
      "Victim Compress Model Test: Accuracy 73.213, Loss 1.049\n"
     ]
    }
   ],
   "source": [
    "victim_compress_model_list = []\n",
    "for i in [0.6,0.7,0.8,0.9]:\n",
    "    compress_victim_model_save_folder = f\"{save_folder_compress}_{i}/victim_model\"\n",
    "    print(f\"Load Compress Model from {compress_victim_model_save_folder}\")\n",
    "    victim_compress_model = BaseModel(dataset_name, model_name, num_cls=num_cls, input_dim=input_dim, save_folder=compress_victim_model_save_folder, device=device)\n",
    "    victim_compress_model.model.load_state_dict(torch.load(f\"{compress_victim_model_save_folder}/best.pth\"))\n",
    "    victim_compress_model.test(victim_train_loader, \"Victim Compress Model Train\")\n",
    "    victim_compress_model.test(victim_test_loader, \"Victim Compress Model Test\")\n",
    "    victim_compress_model_list.append(victim_compress_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "34bb08c7-1038-487c-91ee-1261c4617146",
   "metadata": {},
   "outputs": [],
   "source": [
    "victim_compress_in_predicts_list = []\n",
    "victim_compress_out_predicts_list = []\n",
    "victim_compress_in_loss_list = []\n",
    "victim_compress_out_loss_list = []\n",
    "victim_compress_in_state_list = []\n",
    "victim_compress_out_state_list = []\n",
    "for victim_compress_model in victim_compress_model_list:\n",
    "    victim_compress_in_loss,victim_in_target, victim_compress_in_predicts,victim_compress_in_state = victim_compress_model.predict_target_loss(victim_train_loader)\n",
    "    victim_compress_out_loss, victim_out_target, victim_compress_out_predicts,victim_compress_out_state = victim_compress_model.predict_target_loss(victim_test_loader)\n",
    "    \n",
    "    victim_compress_in_predicts =  victim_compress_in_predicts.gather(1, sort_victim_original_in)\n",
    "    victim_compress_in_predicts = victim_original_in_predicts - victim_compress_in_predicts\n",
    "    victim_compress_out_predicts =  victim_compress_out_predicts.gather(1, sort_victim_original_out)\n",
    "    victim_compress_out_predicts = victim_original_out_predicts - victim_compress_out_predicts\n",
    "    \n",
    "    victim_compress_in_predicts_list.append(victim_compress_in_predicts)\n",
    "    victim_compress_out_predicts_list.append(victim_compress_out_predicts)\n",
    "    victim_compress_in_loss_list.append(victim_compress_in_loss)\n",
    "    victim_compress_out_loss_list.append(victim_compress_out_loss)\n",
    "    victim_compress_in_state_list.append(victim_compress_in_state)\n",
    "    victim_compress_out_state_list.append(victim_compress_out_state)\n",
    "victim_compress_in_loss_list = [x.unsqueeze(1) for x in victim_compress_in_loss_list]  \n",
    "victim_compress_out_loss_list = [x.unsqueeze(1) for x in victim_compress_out_loss_list]  \n",
    "victim_compress_in_state_list = [x.unsqueeze(1) for x in victim_compress_in_state_list]  \n",
    "victim_compress_out_state_list = [x.unsqueeze(1) for x in victim_compress_out_state_list]  \n",
    "victim_compress_in_predicts = torch.cat(victim_compress_in_predicts_list, dim=1)\n",
    "victim_compress_out_predicts = torch.cat(victim_compress_out_predicts_list, dim=1)\n",
    "victim_compress_in_loss = torch.cat(victim_compress_in_loss_list, dim=1)\n",
    "victim_compress_out_loss = torch.cat(victim_compress_out_loss_list, dim=1)\n",
    "victim_compress_in_state = torch.cat(victim_compress_in_state_list, dim=1)\n",
    "victim_compress_out_state = torch.cat(victim_compress_out_state_list, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "37d4dee9-c0e0-48c2-812b-9b7563d4fb74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Victim Train Size: 8000, Victim Test Size: 8000\n",
      "v-------------\n",
      "Load Pruned Shadow Model From results_pruned/1_mini_imagenet_vgg16_l1unstructure_0.6/shadow_model_0\n",
      "v-------------\n",
      "Shadow Pruned Model Train: Accuracy 92.263, Loss 0.293\n",
      "Shadow Pruned Model Test: Accuracy 74.162, Loss 1.115\n",
      "Load Pruned Shadow Model From results_pruned/1_mini_imagenet_vgg16_l1unstructure_0.7/shadow_model_0\n",
      "v-------------\n",
      "Shadow Pruned Model Train: Accuracy 90.487, Loss 0.379\n",
      "Shadow Pruned Model Test: Accuracy 73.500, Loss 1.070\n",
      "Load Pruned Shadow Model From results_pruned/1_mini_imagenet_vgg16_l1unstructure_0.8/shadow_model_0\n",
      "v-------------\n",
      "Shadow Pruned Model Train: Accuracy 91.175, Loss 0.337\n",
      "Shadow Pruned Model Test: Accuracy 73.900, Loss 1.063\n",
      "Load Pruned Shadow Model From results_pruned/1_mini_imagenet_vgg16_l1unstructure_0.9/shadow_model_0\n",
      "v-------------\n",
      "Shadow Pruned Model Train: Accuracy 88.487, Loss 0.456\n",
      "Shadow Pruned Model Test: Accuracy 73.362, Loss 1.038\n",
      "Victim Train Size: 8000, Victim Test Size: 8000\n",
      "v-------------\n",
      "Load Pruned Shadow Model From results_pruned/1_mini_imagenet_vgg16_l1unstructure_0.6/shadow_model_1\n",
      "v-------------\n",
      "Shadow Pruned Model Train: Accuracy 92.025, Loss 0.303\n",
      "Shadow Pruned Model Test: Accuracy 74.025, Loss 1.083\n",
      "Load Pruned Shadow Model From results_pruned/1_mini_imagenet_vgg16_l1unstructure_0.7/shadow_model_1\n",
      "v-------------\n",
      "Shadow Pruned Model Train: Accuracy 90.650, Loss 0.367\n",
      "Shadow Pruned Model Test: Accuracy 73.612, Loss 1.080\n",
      "Load Pruned Shadow Model From results_pruned/1_mini_imagenet_vgg16_l1unstructure_0.8/shadow_model_1\n",
      "v-------------\n",
      "Shadow Pruned Model Train: Accuracy 90.700, Loss 0.368\n",
      "Shadow Pruned Model Test: Accuracy 73.825, Loss 1.049\n",
      "Load Pruned Shadow Model From results_pruned/1_mini_imagenet_vgg16_l1unstructure_0.9/shadow_model_1\n",
      "v-------------\n",
      "Shadow Pruned Model Train: Accuracy 87.662, Loss 0.491\n",
      "Shadow Pruned Model Test: Accuracy 72.950, Loss 1.015\n",
      "Victim Train Size: 8000, Victim Test Size: 8000\n",
      "v-------------\n",
      "Load Pruned Shadow Model From results_pruned/1_mini_imagenet_vgg16_l1unstructure_0.6/shadow_model_2\n",
      "v-------------\n",
      "Shadow Pruned Model Train: Accuracy 90.850, Loss 0.362\n",
      "Shadow Pruned Model Test: Accuracy 73.287, Loss 1.072\n",
      "Load Pruned Shadow Model From results_pruned/1_mini_imagenet_vgg16_l1unstructure_0.7/shadow_model_2\n",
      "v-------------\n",
      "Shadow Pruned Model Train: Accuracy 91.950, Loss 0.313\n",
      "Shadow Pruned Model Test: Accuracy 73.812, Loss 1.099\n",
      "Load Pruned Shadow Model From results_pruned/1_mini_imagenet_vgg16_l1unstructure_0.8/shadow_model_2\n",
      "v-------------\n",
      "Shadow Pruned Model Train: Accuracy 89.475, Loss 0.411\n",
      "Shadow Pruned Model Test: Accuracy 73.237, Loss 1.078\n",
      "Load Pruned Shadow Model From results_pruned/1_mini_imagenet_vgg16_l1unstructure_0.9/shadow_model_2\n",
      "v-------------\n",
      "Shadow Pruned Model Train: Accuracy 88.075, Loss 0.471\n",
      "Shadow Pruned Model Test: Accuracy 72.925, Loss 1.037\n",
      "Victim Train Size: 8000, Victim Test Size: 8000\n",
      "v-------------\n",
      "Load Pruned Shadow Model From results_pruned/1_mini_imagenet_vgg16_l1unstructure_0.6/shadow_model_3\n",
      "v-------------\n",
      "Shadow Pruned Model Train: Accuracy 90.412, Loss 0.363\n",
      "Shadow Pruned Model Test: Accuracy 73.425, Loss 1.127\n",
      "Load Pruned Shadow Model From results_pruned/1_mini_imagenet_vgg16_l1unstructure_0.7/shadow_model_3\n",
      "v-------------\n",
      "Shadow Pruned Model Train: Accuracy 92.100, Loss 0.310\n",
      "Shadow Pruned Model Test: Accuracy 73.787, Loss 1.133\n",
      "Load Pruned Shadow Model From results_pruned/1_mini_imagenet_vgg16_l1unstructure_0.8/shadow_model_3\n",
      "v-------------\n",
      "Shadow Pruned Model Train: Accuracy 90.513, Loss 0.365\n",
      "Shadow Pruned Model Test: Accuracy 73.638, Loss 1.110\n",
      "Load Pruned Shadow Model From results_pruned/1_mini_imagenet_vgg16_l1unstructure_0.9/shadow_model_3\n",
      "v-------------\n",
      "Shadow Pruned Model Train: Accuracy 87.662, Loss 0.486\n",
      "Shadow Pruned Model Test: Accuracy 72.825, Loss 1.071\n",
      "Victim Train Size: 8000, Victim Test Size: 8000\n",
      "v-------------\n",
      "Load Pruned Shadow Model From results_pruned/1_mini_imagenet_vgg16_l1unstructure_0.6/shadow_model_4\n",
      "v-------------\n",
      "Shadow Pruned Model Train: Accuracy 92.400, Loss 0.294\n",
      "Shadow Pruned Model Test: Accuracy 73.213, Loss 1.153\n",
      "Load Pruned Shadow Model From results_pruned/1_mini_imagenet_vgg16_l1unstructure_0.7/shadow_model_4\n",
      "v-------------\n",
      "Shadow Pruned Model Train: Accuracy 91.112, Loss 0.347\n",
      "Shadow Pruned Model Test: Accuracy 72.800, Loss 1.143\n",
      "Load Pruned Shadow Model From results_pruned/1_mini_imagenet_vgg16_l1unstructure_0.8/shadow_model_4\n",
      "v-------------\n",
      "Shadow Pruned Model Train: Accuracy 91.662, Loss 0.330\n",
      "Shadow Pruned Model Test: Accuracy 72.987, Loss 1.109\n",
      "Load Pruned Shadow Model From results_pruned/1_mini_imagenet_vgg16_l1unstructure_0.9/shadow_model_4\n",
      "v-------------\n",
      "Shadow Pruned Model Train: Accuracy 87.438, Loss 0.490\n",
      "Shadow Pruned Model Test: Accuracy 72.562, Loss 1.071\n"
     ]
    }
   ],
   "source": [
    "shadow_model_list, shadow_train_loader_list, shadow_test_loader_list, shadow_prune_model_group_list = [], [], [], []\n",
    "\n",
    "for shadow_ind in range(shadow_num):\n",
    "    attack_train_list, attack_test_list = inference_attack_split_list[shadow_ind]\n",
    "    print(f\"Victim Train Size: {len(attack_train_list)}, \"\n",
    "        f\"Victim Test Size: {len(attack_test_list)}\")\n",
    "    shadow_train_dataset = Subset(total_dataset, attack_train_list)\n",
    "    shadow_test_dataset = Subset(total_dataset, attack_test_list)\n",
    "    shadow_train_loader = DataLoader(shadow_train_dataset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=False)\n",
    "    shadow_test_loader = DataLoader(shadow_test_dataset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=False)\n",
    "    shadow_model_path = f\"{save_folder_original}/shadow_model_{shadow_ind}/best.pth\"\n",
    "    shadow_model = BaseModel(dataset_name,model_name, num_cls=num_cls, input_dim=input_dim, device=device)\n",
    "    shadow_model.load(shadow_model_path)\n",
    "    shadow_model_list.append(shadow_model)\n",
    "    shadow_train_loader_list.append(shadow_train_loader)\n",
    "    shadow_test_loader_list.append(shadow_test_loader)\n",
    "    shadow_prune_model_list = []\n",
    "    for i in [0.6,0.7,0.8,0.9]:\n",
    "        pruned_shadow_model_save_folder = f\"{save_folder_compress}_{i}/shadow_model_{shadow_ind}\"\n",
    "        print(f\"Load Pruned Shadow Model From {pruned_shadow_model_save_folder}\")\n",
    "        shadow_pruned_model = BaseModel(dataset_name,model_name, num_cls=num_cls, input_dim=input_dim,save_folder=pruned_shadow_model_save_folder, device=device)\n",
    "        #shadow_pruned_model.load(f\"{pruned_shadow_model_save_folder}/best.pth\")\n",
    "        shadow_pruned_model.model.load_state_dict(torch.load(f\"{pruned_shadow_model_save_folder}/best.pth\"))\n",
    "        shadow_pruned_model.test(shadow_train_loader, \"Shadow Pruned Model Train\")\n",
    "        shadow_pruned_model.test(shadow_test_loader, \"Shadow Pruned Model Test\")\n",
    "        shadow_prune_model_list.append(shadow_pruned_model)\n",
    "    shadow_prune_model_group_list.append(shadow_prune_model_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "db8f7a5f-f485-4a64-8455-ee42a016613d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shadow prune model 0 for shadow 1: <base_model.BaseModel object at 0x7f94b0369bd0>\n",
      "Shadow prune model 1 for shadow 1: <base_model.BaseModel object at 0x7f94b302e610>\n",
      "Shadow prune model 2 for shadow 1: <base_model.BaseModel object at 0x7f94b036dc10>\n",
      "Shadow prune model 3 for shadow 1: <base_model.BaseModel object at 0x7f94b02685d0>\n",
      "Shadow prune model 0 for shadow 2: <base_model.BaseModel object at 0x7f94b036b310>\n",
      "Shadow prune model 1 for shadow 2: <base_model.BaseModel object at 0x7f94b298dd50>\n",
      "Shadow prune model 2 for shadow 2: <base_model.BaseModel object at 0x7f95e4153810>\n",
      "Shadow prune model 3 for shadow 2: <base_model.BaseModel object at 0x7f94af319990>\n",
      "Shadow prune model 0 for shadow 3: <base_model.BaseModel object at 0x7f94aed62b90>\n",
      "Shadow prune model 1 for shadow 3: <base_model.BaseModel object at 0x7f94aedd1110>\n",
      "Shadow prune model 2 for shadow 3: <base_model.BaseModel object at 0x7f94aedd8550>\n",
      "Shadow prune model 3 for shadow 3: <base_model.BaseModel object at 0x7f94af7b7a10>\n",
      "Shadow prune model 0 for shadow 4: <base_model.BaseModel object at 0x7f94aef38290>\n",
      "Shadow prune model 1 for shadow 4: <base_model.BaseModel object at 0x7f94aed62450>\n",
      "Shadow prune model 2 for shadow 4: <base_model.BaseModel object at 0x7f95e4168610>\n",
      "Shadow prune model 3 for shadow 4: <base_model.BaseModel object at 0x7f94aef3a850>\n",
      "Shadow prune model 0 for shadow 5: <base_model.BaseModel object at 0x7f94b116ae10>\n",
      "Shadow prune model 1 for shadow 5: <base_model.BaseModel object at 0x7f95e4345210>\n",
      "Shadow prune model 2 for shadow 5: <base_model.BaseModel object at 0x7f94af2376d0>\n",
      "Shadow prune model 3 for shadow 5: <base_model.BaseModel object at 0x7f94aef9d610>\n"
     ]
    }
   ],
   "source": [
    "attack_original_in_predicts_list, attack_original_out_predicts_list = [], []\n",
    "attack_pruned_in_predicts_list, attack_pruned_out_predicts_list = [], []\n",
    "attack_original_in_loss_list, attack_original_out_loss_list = [], []\n",
    "attack_pruned_in_loss_list, attack_pruned_out_loss_list = [], []\n",
    "attack_in_targets_list = []\n",
    "attack_out_targets_list= []\n",
    "\n",
    "n = 0\n",
    "\n",
    "for shadow_model, shadow_train_loader, shadow_test_loader in zip(shadow_model_list, shadow_train_loader_list, shadow_test_loader_list):\n",
    "\n",
    "    attack_original_in_loss,attack_in_target, attack_original_in_predicts,attack_original_in_state = shadow_model.predict_target_loss(shadow_train_loader)\n",
    "    attack_original_out_loss, attack_out_target, attack_original_out_predicts,attack_original_out_state = shadow_model.predict_target_loss(shadow_test_loader)\n",
    "\n",
    "    sort_attack_original_in = torch.argsort(attack_original_in_predicts, dim=1, descending=False)\n",
    "    sort_attack_original_out = torch.argsort(attack_original_out_predicts, dim=1, descending=False)\n",
    "    attack_original_in_predicts = torch.gather(attack_original_in_predicts, 1, sort_attack_original_in)\n",
    "    attack_original_out_predicts = torch.gather(attack_original_out_predicts, 1, sort_attack_original_out)\n",
    "    \n",
    "    attack_original_in_loss = attack_original_in_loss.unsqueeze(1)\n",
    "    attack_original_out_loss = attack_original_out_loss.unsqueeze(1)\n",
    "    \n",
    "    attack_original_in_loss_list.append(attack_original_in_loss)\n",
    "    attack_original_out_loss_list.append(attack_original_out_loss)\n",
    "    \n",
    "    attack_original_in_predicts_list.append(attack_original_in_predicts)\n",
    "    attack_original_out_predicts_list.append(attack_original_out_predicts) \n",
    "    attack_in_targets_list.append(attack_in_target)\n",
    "    attack_out_targets_list.append(attack_out_target)  \n",
    "\n",
    "    each_attack_pruned_in_predicts_list = []\n",
    "    each_attack_pruned_out_predicts_list = []\n",
    "    each_attack_pruned_in_loss_list = []\n",
    "    each_attack_pruned_out_loss_list = []\n",
    "\n",
    "    shadow_prune_models_for_n = shadow_prune_model_group_list[n]\n",
    "    n = n+1\n",
    "    for i, shadow_prune_model in enumerate(shadow_prune_models_for_n):\n",
    "        print(f\"Shadow prune model {i} for shadow {n}: {shadow_prune_model}\")\n",
    "        attack_pruned_out_loss, attack_out_targets, attack_pruned_out_predicts,attack_pruned_out_state = shadow_pruned_model.predict_target_loss(shadow_test_loader)\n",
    "        attack_pruned_in_loss, attack_in_targets, attack_pruned_in_predicts,attack_pruned_in_state = shadow_pruned_model.predict_target_loss(shadow_train_loader)\n",
    "\n",
    "        attack_pruned_in_predicts = attack_pruned_in_predicts.gather(1, sort_attack_original_in)\n",
    "        attack_pruned_out_predicts =  attack_pruned_out_predicts.gather(1, sort_attack_original_out)\n",
    "        \n",
    "        attack_pruned_in_predicts = attack_original_in_predicts - attack_pruned_in_predicts\n",
    "        attack_pruned_out_predicts = attack_original_out_predicts - attack_pruned_out_predicts\n",
    "        \n",
    "        each_attack_pruned_out_predicts_list.append(attack_pruned_out_predicts)\n",
    "        each_attack_pruned_in_predicts_list.append(attack_pruned_in_predicts)\n",
    "\n",
    "        each_attack_pruned_in_loss_list.append(attack_pruned_in_loss)\n",
    "        each_attack_pruned_out_loss_list.append(attack_pruned_out_loss)\n",
    "\n",
    "        \n",
    "    each_attack_pruned_in_loss_list = [x.unsqueeze(1) for x in each_attack_pruned_in_loss_list]  # 增加一个维度\n",
    "    each_attack_pruned_out_loss_list = [x.unsqueeze(1) for x in each_attack_pruned_out_loss_list]  # 增加一个维度\n",
    "\n",
    "    each_attack_pruned_in_predicts = torch.cat(each_attack_pruned_in_predicts_list, dim=1)\n",
    "    each_attack_pruned_out_predicts = torch.cat(each_attack_pruned_out_predicts_list, dim=1)\n",
    "    attack_pruned_in_predicts_list.append(each_attack_pruned_in_predicts)\n",
    "    attack_pruned_out_predicts_list.append(each_attack_pruned_out_predicts)\n",
    "\n",
    "    each_attack_pruned_in_loss = torch.cat(each_attack_pruned_in_loss_list, dim=1)\n",
    "    each_attack_pruned_out_loss = torch.cat(each_attack_pruned_out_loss_list, dim=1)\n",
    "    attack_pruned_in_loss_list.append(each_attack_pruned_in_loss)\n",
    "    attack_pruned_out_loss_list.append(each_attack_pruned_out_loss)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "attack_original_in_predicts = torch.cat(attack_original_in_predicts_list, dim=0)\n",
    "attack_original_out_predicts = torch.cat(attack_original_out_predicts_list, dim=0)\n",
    "attack_pruned_in_predicts = torch.cat(attack_pruned_in_predicts_list, dim=0)\n",
    "attack_pruned_out_predicts = torch.cat(attack_pruned_out_predicts_list, dim=0)\n",
    "attack_in_targets = torch.cat(attack_in_targets_list, dim=0)\n",
    "attack_out_targets = torch.cat(attack_out_targets_list, dim=0)\n",
    "\n",
    "attack_original_in_loss = torch.cat(attack_original_in_loss_list, dim=0)\n",
    "attack_original_out_loss = torch.cat(attack_original_out_loss_list, dim=0)\n",
    "\n",
    "attack_pruned_in_loss = torch.cat(attack_pruned_in_loss_list, dim=0)\n",
    "attack_pruned_out_loss = torch.cat(attack_pruned_out_loss_list, dim=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7c8d9213-c02f-4c1b-861c-f9007cae848d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nu = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "43f63d8a-0ea1-479e-a03e-78d7031dea47",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pre = np.concatenate((attack_pruned_in_predicts, attack_pruned_out_predicts), axis=0)\n",
    "test_pre = np.concatenate((victim_compress_in_predicts, victim_compress_out_predicts), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8d8f1a28-a300-4ac3-b2d0-55cc594c1f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "attack_in_targets = F.one_hot(attack_in_targets, num_classes=num_cls).float() \n",
    "attack_out_targets = F.one_hot(attack_out_targets, num_classes=num_cls).float()\n",
    "train_target = np.concatenate((attack_in_targets.cpu(), attack_out_targets.cpu()), axis=0)\n",
    "\n",
    "victim_in_targets = F.one_hot(victim_in_target, num_classes=num_cls).float()\n",
    "victim_out_targets = F.one_hot(victim_out_target, num_classes=num_cls).float()\n",
    "test_target = np.concatenate((victim_in_targets.cpu(), victim_out_targets.cpu()), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "81f6b5fb-a807-41dc-8318-df8445031721",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = np.concatenate((attack_pruned_in_loss, attack_pruned_out_loss), axis=0)\n",
    "test_loss = np.concatenate((victim_compress_in_loss, victim_compress_out_loss), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2aff79bd-f000-40e7-9514-a7bd91e747e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([80000])\n",
      "torch.Size([16000])\n"
     ]
    }
   ],
   "source": [
    "num = len(attack_in_targets)\n",
    "total_num = num*shadow_num \n",
    "ones = torch.ones(total_num)\n",
    "zeros = torch.zeros(total_num)\n",
    "train_labels = torch.cat((ones, zeros), dim=0)\n",
    "print(train_labels.shape)\n",
    "\n",
    "ones = torch.ones(num)\n",
    "zeros = torch.zeros(num)\n",
    "test_labels = torch.cat((ones, zeros), dim=0)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e65079",
   "metadata": {},
   "outputs": [],
   "source": [
    "attack_model_name = \"RF\"\n",
    "method_name = \"compleak_SR2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b516c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "results2 = pd.read_csv(f\"results_compress/{dataset_name}_{model_name}_l1unstructure_0.6/prob_results.csv\")\n",
    "condition2 = (results2['method'] == method_name) & (results2['attack_model_name'] == attack_model_name)\n",
    "prob2 = results2[condition2]\n",
    "train_prob2 = prob2['train_prob'].values[0] \n",
    "test_prob2 = prob2['test_prob'].values[0] \n",
    "train_prob2  = ast.literal_eval(train_prob2)\n",
    "test_prob2  = ast.literal_eval(test_prob2)\n",
    "train_prob2  = np.array(train_prob2).reshape(-1, 2)\n",
    "test_prob2  = np.array(test_prob2).reshape(-1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e8986d",
   "metadata": {},
   "outputs": [],
   "source": [
    "results3 = pd.read_csv(f\"results_compress/{dataset_name}_{model_name}_l1unstructure_0.7/prob_results.csv\")\n",
    "condition3 = (results3['method'] == method_name) & (results3['attack_model_name'] == attack_model_name)\n",
    "prob3 = results3[condition3]\n",
    "train_prob3 = prob3['train_prob'].values[0] \n",
    "test_prob3 = prob3['test_prob'].values[0] \n",
    "train_prob3  = ast.literal_eval(train_prob3)\n",
    "test_prob3  = ast.literal_eval(test_prob3)\n",
    "train_prob3  = np.array(train_prob3).reshape(-1, 2)\n",
    "test_prob3  = np.array(test_prob3).reshape(-1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2819d3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "results4 = pd.read_csv(f\"results_compress/{dataset_name}_{model_name}_l1unstructure_0.8/prob_results.csv\")\n",
    "condition4 = (results4['method'] == method_name) & (results4['attack_model_name'] == attack_model_name)\n",
    "\n",
    "prob4 = results4[condition4]\n",
    "train_prob4 = prob4['train_prob'].values[0] \n",
    "test_prob4 = prob4['test_prob'].values[0] \n",
    "train_prob4  = ast.literal_eval(train_prob4)\n",
    "test_prob4  = ast.literal_eval(test_prob4)\n",
    "train_prob4  = np.array(train_prob4).reshape(-1, 2)\n",
    "test_prob4  = np.array(test_prob4).reshape(-1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7acb405f",
   "metadata": {},
   "outputs": [],
   "source": [
    "results5 = pd.read_csv(f\"results_compress/{dataset_name}_{model_name}_l1unstructure_0.9/prob_results.csv\")\n",
    "condition5 = (results5['method'] == method_name) & (results5['attack_model_name'] == attack_model_name)\n",
    "prob5 = results5[condition5]\n",
    "train_prob5 = prob5['train_prob'].values[0] \n",
    "test_prob5 = prob5['test_prob'].values[0] \n",
    "\n",
    "train_prob5  = ast.literal_eval(train_prob5)\n",
    "test_prob5 = ast.literal_eval(test_prob5)\n",
    "\n",
    "train_prob5  = np.array(train_prob5).reshape(-1, 2)\n",
    "test_prob5  = np.array(test_prob5).reshape(-1, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee7a76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_combined = np.concatenate((train_prob2, train_prob3,train_prob4,train_prob5), axis=1) \n",
    "test_combined = np.concatenate((test_prob2, test_prob3,test_prob4,test_prob5), axis=1)\n",
    "traindata = torch.tensor(train_combined, dtype=torch.float32)\n",
    "testdata = torch.tensor(test_combined, dtype=torch.float32)\n",
    "print(testdata.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7372b2ab-53db-48a8-bdf3-0f10956ec344",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data1, data2,labels):\n",
    "        self.data1 = data1\n",
    "        self.data2 = data2\n",
    "        self.labels = labels\n",
    "    def __len__(self):\n",
    "        return len(self.data1)\n",
    "    def __getitem__(self, idx):\n",
    "        data1 = self.data1[idx]\n",
    "        data2 = self.data2[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        return data1, data2, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e075dcea-5f72-4002-b15d-9f5dcbc14a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(traindata, train_loss, train_labels)\n",
    "test_dataset = CustomDataset(testdata,test_loss,test_labels)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b6868ac5-9d3d-4af7-8777-b28106610668",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "class AttackModel(nn.Module):\n",
    "    def __init__(self, class_num):\n",
    "        super(AttackModel, self).__init__()\n",
    "\n",
    "        # self.dropout = nn.Dropout(p=0.2)\n",
    "        self.output_component = nn.Sequential(\n",
    "            nn.Linear(2*4, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(128, 64),\n",
    "        )\n",
    "\n",
    "        self.loss_component = nn.Sequential(\n",
    "            nn.Linear(1*4, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(128, 64),\n",
    "        )\n",
    "\n",
    "        \n",
    "        self.encoder_component = nn.Sequential(\n",
    "           nn.Dropout(p=0.5),\n",
    "            nn.Linear(64*2 , 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(64, 2),\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, output, loss):\n",
    "        output_component_result = self.output_component(output)\n",
    "        loss_component_result = self.loss_component(loss)\n",
    "        final_input = torch.cat((output_component_result, loss_component_result), 1)\n",
    "        final_result = self.encoder_component(final_input)\n",
    "        return final_result, final_input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "acd6dc83-83dd-4f8e-8805-ab9d11946c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import interp1d\n",
    "def train_mia_attack_model(model, attack_train_loader, optimizer, loss_fn, device):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    for batch_idx, (input1,input2, member_status) in enumerate(attack_train_loader):\n",
    "        input1 = input1.to(device)\n",
    "        \n",
    "        #model_loss = loss.view(-1, 1)\n",
    "        input2 = input2.to(device)\n",
    "\n",
    "        output,_ = model(input1,input2)        \n",
    "        member_status = member_status.to(device)\n",
    "        loss = loss_fn(output, member_status.long())\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        pred = output.max(1, keepdim=True)[1]\n",
    "        correct += pred.eq(member_status.view_as(pred)).sum().item()\n",
    "        \n",
    "    train_loss /= len(attack_train_loader.dataset)\n",
    "    accuracy = 100. * correct / len(attack_train_loader.dataset)\n",
    "    return train_loss, accuracy / 100\n",
    "\n",
    "def test_mia_attack_model(model, attack_test_loader, loss_fn, device):                 \n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    all_ground_truth = []\n",
    "    all_pred_probs = []\n",
    "    final_inputs = []\n",
    "    \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (input1, input2, member_status) in enumerate(attack_test_loader):\n",
    "            input1 = input1.to(device)\n",
    "            input2 = input2.to(device)\n",
    "            #input3 = input3.to(device)\n",
    "            \n",
    "            # 模型输出\n",
    "            output,final_input = model(input1, input2) \n",
    "            final_inputs.append(final_input.detach().cpu())\n",
    "            member_status = member_status.to(device)\n",
    "\n",
    "            \n",
    "            test_loss += loss_fn(output, member_status.long()).item()\n",
    "            \n",
    "            probs = torch.softmax(output, dim=1)[:, 1]  # 提取正类的概率\n",
    "            all_pred_probs.extend(probs.cpu().numpy())  # 保存概率\n",
    "            all_ground_truth.extend(member_status.cpu().numpy())  # 保存真实标签\n",
    "            \n",
    "            pred = output.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(member_status.view_as(pred)).sum().item()\n",
    "    \n",
    "    # 计算平均 loss 和 accuracy\n",
    "    test_loss /= len(attack_test_loader.dataset)\n",
    "    accuracy = 100. * correct / len(attack_test_loader.dataset)\n",
    "    \n",
    "    # 计算 AUC\n",
    "    auc1 = roc_auc_score(all_ground_truth, all_pred_probs)\n",
    "    \n",
    "    # 计算 TPR @ 0.1% FPR\n",
    "    fpr, tpr, thresholds = roc_curve(all_ground_truth, all_pred_probs)\n",
    "\n",
    "    fpr_target = 0.001\n",
    "    interp_func = interp1d(fpr, tpr)\n",
    "    tpr_0 = interp_func(fpr_target)\n",
    "    final_inputs = torch.cat(final_inputs, dim=0)\n",
    "    return test_loss, accuracy / 100., auc1, tpr_0,final_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdceaf2c-55ed-4682-8baf-3c1e13defbdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------mia------------------\n",
      "epoch:0 \t tpr:0.5210 \t test_prec1:0.9472 \t best_prec1:0.9472 \t best_auc:0.9881 \t auc:0.9881\n",
      "epoch:1 \t tpr:0.3614 \t test_prec1:0.9397 \t best_prec1:0.9472 \t best_auc:0.9881 \t auc:0.9866\n",
      "epoch:2 \t tpr:0.2392 \t test_prec1:0.9297 \t best_prec1:0.9472 \t best_auc:0.9881 \t auc:0.9762\n",
      "epoch:3 \t tpr:0.1566 \t test_prec1:0.9346 \t best_prec1:0.9472 \t best_auc:0.9881 \t auc:0.9784\n",
      "epoch:4 \t tpr:0.3910 \t test_prec1:0.9436 \t best_prec1:0.9472 \t best_auc:0.9881 \t auc:0.9870\n",
      "epoch:5 \t tpr:0.3947 \t test_prec1:0.9463 \t best_prec1:0.9472 \t best_auc:0.9881 \t auc:0.9872\n",
      "epoch:6 \t tpr:0.2640 \t test_prec1:0.9400 \t best_prec1:0.9472 \t best_auc:0.9881 \t auc:0.9832\n",
      "epoch:7 \t tpr:0.3125 \t test_prec1:0.9426 \t best_prec1:0.9472 \t best_auc:0.9881 \t auc:0.9840\n",
      "epoch:8 \t tpr:0.4093 \t test_prec1:0.9489 \t best_prec1:0.9489 \t best_auc:0.9884 \t auc:0.9884\n",
      "epoch:9 \t tpr:0.6292 \t test_prec1:0.9498 \t best_prec1:0.9498 \t best_auc:0.9896 \t auc:0.9896\n",
      "epoch:10 \t tpr:0.5603 \t test_prec1:0.9426 \t best_prec1:0.9498 \t best_auc:0.9896 \t auc:0.9891\n",
      "epoch:11 \t tpr:0.2667 \t test_prec1:0.9358 \t best_prec1:0.9498 \t best_auc:0.9896 \t auc:0.9804\n",
      "epoch:12 \t tpr:0.0691 \t test_prec1:0.9297 \t best_prec1:0.9498 \t best_auc:0.9896 \t auc:0.9775\n",
      "epoch:13 \t tpr:0.0333 \t test_prec1:0.9204 \t best_prec1:0.9498 \t best_auc:0.9896 \t auc:0.9670\n",
      "epoch:14 \t tpr:0.0777 \t test_prec1:0.9317 \t best_prec1:0.9498 \t best_auc:0.9896 \t auc:0.9786\n",
      "epoch:15 \t tpr:0.3489 \t test_prec1:0.9444 \t best_prec1:0.9498 \t best_auc:0.9896 \t auc:0.9860\n",
      "epoch:16 \t tpr:0.0586 \t test_prec1:0.9199 \t best_prec1:0.9498 \t best_auc:0.9896 \t auc:0.9689\n",
      "epoch:17 \t tpr:0.1179 \t test_prec1:0.9256 \t best_prec1:0.9498 \t best_auc:0.9896 \t auc:0.9738\n",
      "epoch:18 \t tpr:0.0167 \t test_prec1:0.9072 \t best_prec1:0.9498 \t best_auc:0.9896 \t auc:0.9499\n",
      "epoch:19 \t tpr:0.3287 \t test_prec1:0.9425 \t best_prec1:0.9498 \t best_auc:0.9896 \t auc:0.9844\n",
      "epoch:20 \t tpr:0.2807 \t test_prec1:0.9381 \t best_prec1:0.9498 \t best_auc:0.9896 \t auc:0.9824\n",
      "epoch:21 \t tpr:0.1513 \t test_prec1:0.9362 \t best_prec1:0.9498 \t best_auc:0.9896 \t auc:0.9806\n",
      "epoch:22 \t tpr:0.1224 \t test_prec1:0.9344 \t best_prec1:0.9498 \t best_auc:0.9896 \t auc:0.9780\n",
      "epoch:23 \t tpr:0.1589 \t test_prec1:0.9370 \t best_prec1:0.9498 \t best_auc:0.9896 \t auc:0.9814\n",
      "epoch:24 \t tpr:0.3340 \t test_prec1:0.9456 \t best_prec1:0.9498 \t best_auc:0.9896 \t auc:0.9860\n",
      "epoch:25 \t tpr:0.0612 \t test_prec1:0.9334 \t best_prec1:0.9498 \t best_auc:0.9896 \t auc:0.9724\n",
      "epoch:26 \t tpr:0.3543 \t test_prec1:0.9419 \t best_prec1:0.9498 \t best_auc:0.9896 \t auc:0.9859\n",
      "epoch:27 \t tpr:0.1267 \t test_prec1:0.9322 \t best_prec1:0.9498 \t best_auc:0.9896 \t auc:0.9755\n",
      "epoch:28 \t tpr:0.0167 \t test_prec1:0.9021 \t best_prec1:0.9498 \t best_auc:0.9896 \t auc:0.9436\n",
      "epoch:29 \t tpr:0.0346 \t test_prec1:0.9161 \t best_prec1:0.9498 \t best_auc:0.9896 \t auc:0.9613\n",
      "epoch:30 \t tpr:0.1030 \t test_prec1:0.9330 \t best_prec1:0.9498 \t best_auc:0.9896 \t auc:0.9757\n",
      "epoch:31 \t tpr:0.3476 \t test_prec1:0.9491 \t best_prec1:0.9498 \t best_auc:0.9896 \t auc:0.9875\n",
      "epoch:32 \t tpr:0.0437 \t test_prec1:0.9196 \t best_prec1:0.9498 \t best_auc:0.9896 \t auc:0.9621\n",
      "epoch:33 \t tpr:0.0400 \t test_prec1:0.9304 \t best_prec1:0.9498 \t best_auc:0.9896 \t auc:0.9717\n",
      "epoch:34 \t tpr:0.1724 \t test_prec1:0.9411 \t best_prec1:0.9498 \t best_auc:0.9896 \t auc:0.9810\n",
      "epoch:35 \t tpr:0.1015 \t test_prec1:0.9328 \t best_prec1:0.9498 \t best_auc:0.9896 \t auc:0.9775\n",
      "epoch:36 \t tpr:0.3529 \t test_prec1:0.9471 \t best_prec1:0.9498 \t best_auc:0.9896 \t auc:0.9870\n",
      "epoch:37 \t tpr:0.2180 \t test_prec1:0.9394 \t best_prec1:0.9498 \t best_auc:0.9896 \t auc:0.9836\n",
      "epoch:38 \t tpr:0.3335 \t test_prec1:0.9459 \t best_prec1:0.9498 \t best_auc:0.9896 \t auc:0.9863\n",
      "epoch:39 \t tpr:0.2588 \t test_prec1:0.9363 \t best_prec1:0.9498 \t best_auc:0.9896 \t auc:0.9812\n",
      "epoch:40 \t tpr:0.3379 \t test_prec1:0.9447 \t best_prec1:0.9498 \t best_auc:0.9896 \t auc:0.9851\n",
      "epoch:41 \t tpr:0.1059 \t test_prec1:0.9354 \t best_prec1:0.9498 \t best_auc:0.9896 \t auc:0.9777\n",
      "epoch:42 \t tpr:0.3548 \t test_prec1:0.9439 \t best_prec1:0.9498 \t best_auc:0.9896 \t auc:0.9854\n",
      "epoch:43 \t tpr:0.0407 \t test_prec1:0.9091 \t best_prec1:0.9498 \t best_auc:0.9896 \t auc:0.9562\n",
      "epoch:44 \t tpr:0.2409 \t test_prec1:0.9404 \t best_prec1:0.9498 \t best_auc:0.9896 \t auc:0.9817\n",
      "epoch:45 \t tpr:0.1010 \t test_prec1:0.9234 \t best_prec1:0.9498 \t best_auc:0.9896 \t auc:0.9709\n",
      "epoch:46 \t tpr:0.0428 \t test_prec1:0.9303 \t best_prec1:0.9498 \t best_auc:0.9896 \t auc:0.9692\n",
      "epoch:47 \t tpr:0.2077 \t test_prec1:0.9424 \t best_prec1:0.9498 \t best_auc:0.9896 \t auc:0.9838\n",
      "epoch:48 \t tpr:0.2310 \t test_prec1:0.9437 \t best_prec1:0.9498 \t best_auc:0.9896 \t auc:0.9839\n",
      "epoch:49 \t tpr:0.0981 \t test_prec1:0.9354 \t best_prec1:0.9498 \t best_auc:0.9896 \t auc:0.9774\n",
      "epoch:50 \t tpr:0.0214 \t test_prec1:0.9014 \t best_prec1:0.9498 \t best_auc:0.9896 \t auc:0.9471\n",
      "epoch:51 \t tpr:0.0468 \t test_prec1:0.9284 \t best_prec1:0.9498 \t best_auc:0.9896 \t auc:0.9684\n",
      "epoch:52 \t tpr:0.0186 \t test_prec1:0.9115 \t best_prec1:0.9498 \t best_auc:0.9896 \t auc:0.9520\n",
      "epoch:53 \t tpr:0.0210 \t test_prec1:0.9087 \t best_prec1:0.9498 \t best_auc:0.9896 \t auc:0.9474\n",
      "epoch:54 \t tpr:0.0422 \t test_prec1:0.9210 \t best_prec1:0.9498 \t best_auc:0.9896 \t auc:0.9624\n",
      "epoch:55 \t tpr:0.0300 \t test_prec1:0.9127 \t best_prec1:0.9498 \t best_auc:0.9896 \t auc:0.9563\n",
      "epoch:56 \t tpr:0.0263 \t test_prec1:0.9158 \t best_prec1:0.9498 \t best_auc:0.9896 \t auc:0.9560\n",
      "epoch:57 \t tpr:0.0814 \t test_prec1:0.9283 \t best_prec1:0.9498 \t best_auc:0.9896 \t auc:0.9708\n",
      "epoch:58 \t tpr:0.1472 \t test_prec1:0.9402 \t best_prec1:0.9498 \t best_auc:0.9896 \t auc:0.9815\n",
      "epoch:59 \t tpr:0.0285 \t test_prec1:0.9134 \t best_prec1:0.9498 \t best_auc:0.9896 \t auc:0.9559\n",
      "epoch:60 \t tpr:0.0268 \t test_prec1:0.9062 \t best_prec1:0.9498 \t best_auc:0.9896 \t auc:0.9544\n",
      "epoch:61 \t tpr:0.0260 \t test_prec1:0.9161 \t best_prec1:0.9498 \t best_auc:0.9896 \t auc:0.9576\n",
      "epoch:62 \t tpr:0.0825 \t test_prec1:0.9329 \t best_prec1:0.9498 \t best_auc:0.9896 \t auc:0.9753\n",
      "epoch:63 \t tpr:0.0217 \t test_prec1:0.8970 \t best_prec1:0.9498 \t best_auc:0.9896 \t auc:0.9474\n",
      "epoch:64 \t tpr:0.0120 \t test_prec1:0.8802 \t best_prec1:0.9498 \t best_auc:0.9896 \t auc:0.9255\n",
      "epoch:65 \t tpr:0.0174 \t test_prec1:0.9058 \t best_prec1:0.9498 \t best_auc:0.9896 \t auc:0.9470\n",
      "epoch:66 \t tpr:0.0127 \t test_prec1:0.8808 \t best_prec1:0.9498 \t best_auc:0.9896 \t auc:0.9334\n",
      "epoch:67 \t tpr:0.0082 \t test_prec1:0.8646 \t best_prec1:0.9498 \t best_auc:0.9896 \t auc:0.9082\n",
      "epoch:68 \t tpr:0.0064 \t test_prec1:0.8536 \t best_prec1:0.9498 \t best_auc:0.9896 \t auc:0.8903\n",
      "epoch:69 \t tpr:0.0154 \t test_prec1:0.8956 \t best_prec1:0.9498 \t best_auc:0.9896 \t auc:0.9405\n",
      "epoch:70 \t tpr:0.0212 \t test_prec1:0.9073 \t best_prec1:0.9498 \t best_auc:0.9896 \t auc:0.9520\n",
      "epoch:71 \t tpr:0.0219 \t test_prec1:0.9038 \t best_prec1:0.9498 \t best_auc:0.9896 \t auc:0.9500\n",
      "epoch:72 \t tpr:0.0151 \t test_prec1:0.8928 \t best_prec1:0.9498 \t best_auc:0.9896 \t auc:0.9362\n",
      "epoch:73 \t tpr:0.0183 \t test_prec1:0.9004 \t best_prec1:0.9498 \t best_auc:0.9896 \t auc:0.9455\n",
      "epoch:74 \t tpr:0.0081 \t test_prec1:0.8481 \t best_prec1:0.9498 \t best_auc:0.9896 \t auc:0.9018\n",
      "epoch:75 \t tpr:0.0046 \t test_prec1:0.8301 \t best_prec1:0.9498 \t best_auc:0.9896 \t auc:0.8654\n",
      "epoch:76 \t tpr:0.0085 \t test_prec1:0.8719 \t best_prec1:0.9498 \t best_auc:0.9896 \t auc:0.9138\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import roc_auc_score\n",
    "print(f'-------------------mia------------------')\n",
    "attack_model = AttackModel(num_cls)\n",
    "epoch = 100\n",
    "attack_optimizer = torch.optim.SGD(attack_model.parameters(), 1e-1, momentum=0.9, weight_decay=5e-4)\n",
    "attack_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(attack_optimizer, T_max=epoch)\n",
    "attack_model = attack_model.to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "best_prec1 = 0.0\n",
    "best_auc = 0.0\n",
    "for epoch in range(epoch):\n",
    "    train_loss, train_prec1 = train_mia_attack_model(attack_model, train_loader, attack_optimizer, loss_fn, device)\n",
    "    val_loss, val_prec1,auc,tpr_0, final_inputs = test_mia_attack_model(attack_model, test_loader, loss_fn, device)\n",
    "    attack_scheduler.step()\n",
    "    is_best_prec1 = val_prec1 > best_prec1\n",
    "    if is_best_prec1:\n",
    "        best_prec1 = val_prec1\n",
    "        best_auc = auc\n",
    "    print(('epoch:{} \\t tpr:{:.4f} \\t test_prec1:{:.4f} \\t best_prec1:{:.4f} \\t best_auc:{:.4f} \\t auc:{:.4f}')\n",
    "            .format(epoch,tpr_0, val_prec1, best_prec1, best_auc,auc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
